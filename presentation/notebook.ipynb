{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Analysis of the Serial Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## String Matching\n",
    "\n",
    "The algorithms for the search of substrings called pattern-string (of length M), in a larger string called text-string (of length N) are of fundamental importance, and have applications in many different fields. \n",
    "\n",
    "## The Rabin-Karp Algorithm\n",
    "\n",
    "It is an algorithm that uses a rolling-hash function that allows it to achieve performances in the order of O (M + N), with high probability. This is a completely different approach to brute-force, substring searching is based on hashing. \n",
    "\n",
    "### The operations  can be summarized in these few lines:\n",
    "* Compute a hash function for the pattern\n",
    "* Aearch for a match using the same hash function for each possible substring of characters M of the text\n",
    "* If we find a text substring with the same hash value as the pattern, check the match (Note: a matching hash does NOT imply a matching string)\n",
    "\n",
    "## Role of the Rolling-Hash Function:\n",
    "\n",
    "Be aware, however, that a direct implementation based on the above description would be much slower than a brute force search. Computing a hash function involving each character is probably much more expensive than just comparing characters. But Rabin and Karp showed that it is easy to compute hash functions for character substrings M in constant time (after some preprocessing). This leads to a search for substrings in linear time in practical situations, i.e. at the average performance (high probability) we have indicated.\n",
    "\n",
    "## How does the Hash work?\n",
    "\n",
    "The underlying theory is the following: we know that a string of length M corresponds to a base-R number of M digits (R: alphabet size). If I want to use a hash table of size Q for keys of this type, we need a hash function to convert a base-R M-digit number to an int value between 0 and Q-1. Modular hashing can be a good idea:\n",
    "\n",
    "$ hash (x) = x mod Q $\n",
    "\n",
    "\n",
    "Basically, we use $Q$, a random prime number, as large as possible.\n",
    "\n",
    "\n",
    "As already mentioned, Rabin-Karp does not compute hashing on all strings of length M, to find the one with the same hash and then make the comparison. But we use the \"mathematical trick\" exploited by Rabin and Karp.\n",
    "This \"trick\" leads, after preprocessing, to compute hashes in constant time. It exploits Horner's rule which states that it is possible to evaluate a polynomial of degree N by carrying out only N additions and N multiplications. \n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "$ a_{2}* x^{2} + a_{1} * x + ... + a_{0} = (a^{2} * x + a_{1}) * x + a_{0} $\n",
    "\n",
    "\n",
    "This identity holds true for modulo-arithmetics, the one we use for hashing, where the following applies:\n",
    "\n",
    "\n",
    "$ (a_{2} * x^{2} + a_{1} * x + ... + a_{0}) mod z = (((a_{2} * x + a_{1}) mod z) * x + a_{0}) mod z $\n",
    "\n",
    "\n",
    "The Rabin-Karp method is based on efficiently computing the hash function xi+1 for the position i+1 in the text, given its value for position i, xi. Example:\n",
    "\n",
    "$ x_{i}= t_{i} * RM^{-1} + t_{i}+1 * RM^{-2} + ... + t_{i} + M^{-1} * R0\n",
    "x_{i+1} = t_{i+1} * RM + t_{i} * RM^{-1} + ... + t_{i} + M * R0 $\n",
    "\n",
    "$ x_{i+1} = (x_{i} - t_{i} * RM^{-1}) * R + t_{i}+M $\n",
    "\n",
    "We do not have to keep the values ​​of the numbers, only the values ​​of their remainder divided by Q. The algorithm is then used iteratively, calculating the hash of the next string, using that of the previous one as in the formula above.\n",
    "\n",
    "Once we find a hash value for a substring of text of characters M that matches the hash value of the pattern, we do not test for match or collision. Matching requires M to be matched against the text string and this degrades performance. But if we make Q very large, we make the probability of a collision extremely small. With a Q value greater than 10 20, we make the probability of a collision equal to 10 -20.\n",
    "\n",
    "This algorithm is a first and famous example of a Monte Carlo algorithm that has a guaranteed completion time but fails to provide a correct answer with a small probability.\n",
    "\n",
    "In our implementation of the algorithm, we actually do check the pattern against the substring each time their hashes match. This is due to the fact that using a very large Q-value can lead to overflows, or slow down the execution. This means that once a match is found by our program, it’s guaranteed to be a match.\n",
    "\n",
    "<img src=\"./images/a.png\" width=\"300\"></img>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) A Priori Study of Available Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "As aforementioned, the Rabin-Karb algorithm for string-matching uses a rolling-hash to avoid having to repeat the computation of the hash for each window of text from scratch, and to achieve linear time complecity in the best case scenario.\n",
    "\n",
    "<img src=\"http://img.sparknotes.com/figures/E/e06912cfeeac4cade7d4527506538c17/rabin1.gif\" width=\"300\"></img>\n",
    "\n",
    "This effectively means that there's always a data-dependency between the current iteration and the one preceding it. In particular, this is an instance of a  **loop-carried dependence**: *statements in an iteration of a loop depend on statements in another iteration of the loop*. The presence of this dependence makes it hard to parallelize the algorithm itself: we cannot use the loop-unrolling technique. \n",
    "\n",
    "### Our Solution\n",
    "\n",
    "The approach we resorted to, was to split the text into N parts (or N \"sub-texts\"), where N is the number of slave processes, and to assign a 'sub-text' to each slave process. \n",
    "\n",
    "#### Role of the Master Process\n",
    "\n",
    "The master process starts out by reading the full text and the pattern to be searched in it. It splits the text into N parts of equal length, and sends each part to a slave, togheter with the pattern, which is the same for everyone. \n",
    "\n",
    "Then the master waits for each slave process to return its result, ie: the number of occurences found in a slave's sub-text. \n",
    "\n",
    "#### Role of the Slave Processes\n",
    "\n",
    "A slave probes the size of the incoming message, using MPI_Probe and MPI_Get_count. It then allocates enough space in memory to store its assigned sub-text and the pattern to be searched for. \n",
    "\n",
    "The message from the master is a single string that includes both the sub-text and the pattern, separated by a designated char (that obviously can't appear in the text). \n",
    "\n",
    "The slave runs Rabin-Karp on the sub-text and the pattern, calling back the master when it is done searching, and returning its result.\n",
    "\n",
    "#### Working Hypothesis\n",
    "\n",
    "Assuming that the subtext is much larger than the pattern, we can neglect the remainder of the int division between text size and number of slaves. \n",
    "\n",
    "##### For example:\n",
    "\n",
    "* $ N = 7 $ (Number of slave processes, using N+1 cores).\n",
    "* $ M = 1000 $ (Size of the pattern).\n",
    "* $ T = 1000000 $ (Size of the full text).\n",
    "\n",
    "$ T mod N = 1 << M $       \n",
    "\n",
    "Hence it's not worth it, or even possible, to search for a pattern of size M in a portion the text of size $ T mod N $.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating 'S' and 'P' for Amdahl's law equation\n",
    "\n",
    "Assuming that the ratio of C-slocs to Asm-slocs is approximately constant throughout the codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lines of C/C++ Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(pathname):\n",
    "    import re\n",
    "    with open(pathname, \"r\") as f:\n",
    "        source = f.read()\n",
    "    source = source.split(\"\\n\") \n",
    "    source = [line for line in source if len(line.strip()) > 0 ]\n",
    "    source = [re.sub(\"\\\\s+\", \"\", line) for line in source]\n",
    "    source = [line for line in source if line[:2] != '//'  ]\n",
    "    return len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38372093023255816, 0.6162790697674418)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the rabin-karp part and roughly half of the main (slave).\n",
    "parallelizable = count_lines(\"../headers/rabin_karp.h\") +count_lines(\"../parallel2.cpp\")/2\n",
    "\n",
    "# total\n",
    "total = parallelizable + count_lines(\"../parallel2.cpp\")/2 + count_lines(\"../headers/read_file.h\")\n",
    "\n",
    "P = parallelizable/total\n",
    "S = 1-P\n",
    "S, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Amdahl Law's Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = lambda N : 1 / (S + P/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.368330464716007"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speedup(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Assembly slocs\n",
    "(Assuming ratio of C-slocs/Asm-slocs is NOT constant throughout the codebase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decompiling the executable and counting the lines of code used by each part of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpic++ -g -O0 -fno-builtin ../parallel2.cpp -o a.out\n",
    "!  objdump -fsd --source a.out > dump.txt\n",
    "! rm a.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approx. Intervals from dump.txt (objump data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4904109589041096, 0.5095890410958904)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slave =  749 - 604\n",
    "master = 600 - 320\n",
    "main_com = 315 - 277\n",
    "search = 275 - 86\n",
    "read = 79 - 1\n",
    "tot = slave + master + main_com + search + read\n",
    "par = (slave + main_com + search )/ tot\n",
    "ser= 1 - par \n",
    "ser, par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7755385684503127"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speedup = lambda N : 1 / (ser + par/N)\n",
    "speedup(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
